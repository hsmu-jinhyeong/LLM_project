{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916b8bc6",
   "metadata": {},
   "source": [
    "### Loading and Embedding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaed384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RCP_SNO                                RCP_TTL  \\\n",
      "0  7016813                       ë©¸ì¹˜ìœ¡ìˆ˜ ì†Œê³ ê¸° ë–¡êµ­ ë§Œë“œëŠ”ë²•   \n",
      "1  7016814  #ìˆ˜ìœ¡ìš©ì‚¼ê²¹ì‚´ #ëœì¥ìˆ˜ìœ¡ë§Œë“¤ê¸° #ì¼ìƒë¨¹ê±°ë¦¬ #ë¬´ìƒì±„ì™€í•¨ê»˜ë¨¹ëŠ”ëœì¥ìˆ˜ìœ¡   \n",
      "2  7016815                       ìš°ê±°ì§€ê°ìíƒ• ë¼ˆí•´ì¥êµ­ ë“ì´ëŠ”ë²•   \n",
      "3  7016816    ë§Œë‘ì „ê³¨ ë ˆì‹œí”¼ ë°±ì¢…ì› ë§Œë‘ ì „ê³¨ìš”ë¦¬ ëœ¨ëˆí•˜ê³  ì§„í•œ êµ­ë¬¼ì´ ì¼í’ˆ   \n",
      "4  7016817     ìƒˆí•´ í†µì‚¼ê²¹ì‚´ ë¬´ìˆ˜ë¶„ ë³´ìŒˆ ì‚¶ëŠ”ë²• ë°±ì¢…ì› ë³´ìŒˆ ë§ˆëŠ˜ì†ŒìŠ¤ ë§Œë“¤ê¸°   \n",
      "\n",
      "                                      RECIPE_CONTENT  \n",
      "0  ë©¸ì¹˜ìœ¡ìˆ˜ ì†Œê³ ê¸° ë–¡êµ­ ë§Œë“œëŠ”ë²•. ì†Œê³ ê¸° ì¬ë£Œ. ìƒˆí•´ê°€ ë˜ë©´ ëœ¨ëˆí•œ ë–¡êµ­ í•œ ê·¸ë¦‡ì´ ...  \n",
      "1  #ìˆ˜ìœ¡ìš©ì‚¼ê²¹ì‚´ #ëœì¥ìˆ˜ìœ¡ë§Œë“¤ê¸° #ì¼ìƒë¨¹ê±°ë¦¬ #ë¬´ìƒì±„ì™€í•¨ê»˜ë¨¹ëŠ”ëœì¥ìˆ˜ìœ¡. ë¼ì§€ê³ ê¸° ì¬ë£Œ...  \n",
      "2  ìš°ê±°ì§€ê°ìíƒ• ë¼ˆí•´ì¥êµ­ ë“ì´ëŠ”ë²•. ë¼ì§€ê³ ê¸° ì¬ë£Œ. ê¹Œë‹¤ë¡œìš´ ë‚¨í¸ì˜ ì…ë§›ì„ ë§ì¶”ê¸°ìœ„í•´ ...  \n",
      "3  ë§Œë‘ì „ê³¨ ë ˆì‹œí”¼ ë°±ì¢…ì› ë§Œë‘ ì „ê³¨ìš”ë¦¬ ëœ¨ëˆí•˜ê³  ì§„í•œ êµ­ë¬¼ì´ ì¼í’ˆ. ê°€ê³µì‹í’ˆë¥˜ ì¬ë£Œ....  \n",
      "4  ìƒˆí•´ í†µì‚¼ê²¹ì‚´ ë¬´ìˆ˜ë¶„ ë³´ìŒˆ ì‚¶ëŠ”ë²• ë°±ì¢…ì› ë³´ìŒˆ ë§ˆëŠ˜ì†ŒìŠ¤ ë§Œë“¤ê¸°. ë¼ì§€ê³ ê¸° ì¬ë£Œ. ì´‰...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def load_recipe_data(file_path):\n",
    "    \"\"\"\n",
    "    ë ˆì‹œí”¼ CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path: CSV íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        ì „ì²˜ë¦¬ëœ DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # ë ˆì‹œí”¼ ì¶”ì²œì„ ìœ„í•œ í†µí•© í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    df['RECIPE_CONTENT'] = (\n",
    "        df['RCP_TTL'].fillna('') + \". \" + \n",
    "        df['CKG_MTRL_ACTO_NM'].fillna('') + \" ì¬ë£Œ. \" + \n",
    "        df['CKG_IPDC'].fillna('') + \" ìƒì„¸ ì„¤ëª…. \" +\n",
    "        \"ì¬ë£Œ ëª©ë¡: \" + df['CKG_MTRL_CN'].fillna('')\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_embedding_data(df):\n",
    "    \"\"\"\n",
    "    ì„ë² ë”©ì— í•„ìš”í•œ ë°ì´í„°í”„ë ˆì„ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        df: ì „ì²´ ë ˆì‹œí”¼ DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        ì„ë² ë”©ìš© DataFrame (RCP_SNO, RCP_TTL, RECIPE_CONTENT)\n",
    "    \"\"\"\n",
    "    return df[['RCP_SNO', 'RCP_TTL', 'RECIPE_CONTENT']].copy()\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„\n",
    "df = load_recipe_data(\"../data/TB_RECIPE_SEARCH_241226.csv\")\n",
    "data_to_embed = prepare_embedding_data(df)\n",
    "print(data_to_embed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ë¥¼ OpenAI ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸\n",
    "        model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸\n",
    "    \n",
    "    Returns:\n",
    "        ì„ë² ë”© ë²¡í„° (list)\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "print(\"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d9b33",
   "metadata": {},
   "source": [
    "### ì„ë² ë”© í…ìŠ¤íŠ¸ ì²­í‚¹ (Chunking)\n",
    "\n",
    "ê¸´ í…ìŠ¤íŠ¸ëŠ” í† í° ì œí•œìœ¼ë¡œ ì¸í•´ ì²­í‚¹ì´ í•„ìš”í•©ë‹ˆë‹¤. OpenAI ì„ë² ë”© ëª¨ë¸ì˜ í† í° ì œí•œê³¼ ì²­í‚¹ ì „ëµì„ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4989222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text: í† í°ì„ ê³„ì‚°í•  í…ìŠ¤íŠ¸\n",
    "        model: ê¸°ì¤€ ëª¨ë¸\n",
    "    \n",
    "    Returns:\n",
    "        í† í° ìˆ˜ (int)\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def analyze_token_statistics(df, content_column='RECIPE_CONTENT'):\n",
    "    \"\"\"\n",
    "    ë ˆì‹œí”¼ ë°ì´í„°ì˜ í† í° í†µê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        df: ë ˆì‹œí”¼ DataFrame\n",
    "        content_column: ë¶„ì„í•  ì»¬ëŸ¼ëª…\n",
    "    \n",
    "    Returns:\n",
    "        í† í° ìˆ˜ê°€ ì¶”ê°€ëœ DataFrame\n",
    "    \"\"\"\n",
    "    df['token_count'] = df[content_column].apply(count_tokens)\n",
    "    \n",
    "    print(\"ğŸ“Š ë ˆì‹œí”¼ í…ìŠ¤íŠ¸ í† í° í†µê³„:\")\n",
    "    print(f\"í‰ê·  í† í° ìˆ˜: {df['token_count'].mean():.0f}\")\n",
    "    print(f\"ìµœëŒ€ í† í° ìˆ˜: {df['token_count'].max()}\")\n",
    "    print(f\"ìµœì†Œ í† í° ìˆ˜: {df['token_count'].min()}\")\n",
    "    print(f\"\\nâš ï¸ 8,191 í† í° ì´ˆê³¼: {(df['token_count'] > 8191).sum()}ê°œ\")\n",
    "    \n",
    "    # ê¸´ í…ìŠ¤íŠ¸ ìƒ˜í”Œ í™•ì¸\n",
    "    if (df['token_count'] > 8191).any():\n",
    "        long_text = df[df['token_count'] > 8191].iloc[0]\n",
    "        print(f\"\\nê¸´ í…ìŠ¤íŠ¸ ì˜ˆì‹œ:\")\n",
    "        print(f\"ì œëª©: {long_text['RCP_TTL']}\")\n",
    "        print(f\"í† í° ìˆ˜: {long_text['token_count']}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# í† í° ë¶„ì„ ì‹¤í–‰\n",
    "data_to_embed = analyze_token_statistics(data_to_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26e5b2",
   "metadata": {},
   "source": [
    "### ì„ íƒëœ ì²­í‚¹ ì „ëµ: í•µì‹¬ ì •ë³´ ì¶”ì¶œ (Essential Info Only)\n",
    "\n",
    "**ì„ íƒ ì´ìœ **:\n",
    "- âœ… ëŒ€ë¶€ë¶„ì˜ ë ˆì‹œí”¼ê°€ í† í° ì œí•œ(8,191) ë¯¸ë§Œ\n",
    "- âœ… ë¹„ìš© íš¨ìœ¨ì : í‰ê·  í† í° ìˆ˜ 70% ê°ì†Œ\n",
    "- âœ… ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ: ì œëª©, ì¬ë£Œ, ì¡°ë¦¬ë²• í•µì‹¬ í‚¤ì›Œë“œë§Œ ì„ë² ë”©\n",
    "\n",
    "**ì ìš© ë°©ë²•**: ë ˆì‹œí”¼ ì œëª© + ì£¼ì¬ë£Œ + ì¬ë£Œ ëª©ë¡(200ì ì œí•œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d25b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_essential_content(row):\n",
    "    \"\"\"\n",
    "    ë ˆì‹œí”¼ì˜ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrameì˜ í•œ í–‰\n",
    "    \n",
    "    Returns:\n",
    "        í•µì‹¬ ì •ë³´ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    essential = (\n",
    "        f\"{row['RCP_TTL']}. \"\n",
    "        f\"{row['CKG_MTRL_ACTO_NM']} ìš”ë¦¬. \"\n",
    "        f\"ì£¼ì¬ë£Œ: {row['CKG_MTRL_CN'][:200]}\"\n",
    "    )\n",
    "    return essential\n",
    "\n",
    "def extract_essential_info(df):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ë ˆì‹œí”¼ ë°ì´í„°ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  íš¨ìœ¨ì„±ì„ ë¹„êµí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        df: ì›ë³¸ ë ˆì‹œí”¼ DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        í•µì‹¬ ì •ë³´ê°€ ì¶”ê°€ëœ DataFrame\n",
    "    \"\"\"\n",
    "    df['ESSENTIAL_CONTENT'] = df.apply(create_essential_content, axis=1)\n",
    "    \n",
    "    # í† í° íš¨ìœ¨ì„± ë¹„êµ\n",
    "    avg_full = df['RECIPE_CONTENT'].apply(count_tokens).mean()\n",
    "    avg_essential = df['ESSENTIAL_CONTENT'].apply(count_tokens).mean()\n",
    "    reduction_rate = (1 - avg_essential / avg_full) * 100\n",
    "    \n",
    "    print(\"âœ… í•µì‹¬ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ\")\n",
    "    print(f\"í‰ê·  í† í° ìˆ˜ (ì „ì²´): {avg_full:.0f}\")\n",
    "    print(f\"í‰ê·  í† í° ìˆ˜ (í•µì‹¬): {avg_essential:.0f}\")\n",
    "    print(f\"í† í° ì ˆê°ë¥ : {reduction_rate:.1f}%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# í•µì‹¬ ì •ë³´ ì¶”ì¶œ\n",
    "data_to_embed = extract_essential_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1f33e9",
   "metadata": {},
   "source": [
    "### ì„ë² ë”© ìƒì„± (í•µì‹¬ ì •ë³´ ì‚¬ìš©)\n",
    "\n",
    "ì´ì œ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•œ `ESSENTIAL_CONTENT`ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(df, content_column='ESSENTIAL_CONTENT', sample_size=100):\n",
    "    \"\"\"\n",
    "    ë ˆì‹œí”¼ ë°ì´í„°ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        df: ë ˆì‹œí”¼ DataFrame\n",
    "        content_column: ì„ë² ë”©í•  ì»¬ëŸ¼ëª…\n",
    "        sample_size: ì„ë² ë”©í•  ìƒ˜í”Œ ê°œìˆ˜ (Noneì´ë©´ ì „ì²´)\n",
    "    \n",
    "    Returns:\n",
    "        ì„ë² ë”©ì´ ì¶”ê°€ëœ DataFrameê³¼ NumPy ë°°ì—´\n",
    "    \"\"\"\n",
    "    # ìƒ˜í”Œ ë°ì´í„° ì„ íƒ\n",
    "    if sample_size:\n",
    "        test_data = df.head(sample_size).copy()\n",
    "        print(f\"ğŸ”„ ì„ë² ë”© ìƒì„± ì‹œì‘ (ìƒ˜í”Œ: {sample_size}ê°œ)...\")\n",
    "    else:\n",
    "        test_data = df.copy()\n",
    "        print(f\"ğŸ”„ ì„ë² ë”© ìƒì„± ì‹œì‘ (ì „ì²´: {len(df)}ê°œ)...\")\n",
    "    \n",
    "    # ì„ë² ë”© ìƒì„±\n",
    "    embeddings = []\n",
    "    total = len(test_data)\n",
    "    \n",
    "    for i, text in enumerate(test_data[content_column]):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"ì§„í–‰: {i}/{total} ({i/total*100:.1f}%)\")\n",
    "        \n",
    "        embedding = get_embedding(text)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    # DataFrameì— ì €ì¥\n",
    "    test_data['embedding'] = embeddings\n",
    "    \n",
    "    # NumPy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    recipe_embeddings = np.array(test_data['embedding'].tolist())\n",
    "    \n",
    "    print(f\"âœ… {len(embeddings)}ê°œ ë ˆì‹œí”¼ ì„ë² ë”© ì™„ë£Œ!\")\n",
    "    print(f\"ì„ë² ë”© í˜•íƒœ: {recipe_embeddings.shape}\")\n",
    "    \n",
    "    return test_data, recipe_embeddings\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±\n",
    "test_data, recipe_embeddings = generate_embeddings(data_to_embed, sample_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63df8fb",
   "metadata": {},
   "source": [
    "### ì„ íƒëœ ë²¡í„° DB: FAISS (ë¡œì»¬ ë²¡í„° ê²€ìƒ‰)\n",
    "\n",
    "**ì„ íƒ ì´ìœ **:\n",
    "- ì™„ì „ ë¬´ë£Œ, ë¡œì»¬ ì‹¤í–‰\n",
    "- ê°€ì¥ ë¹ ë¥¸ ì†ë„ (23,192ê°œ ë ˆì‹œí”¼ ê²€ìƒ‰ ìµœì í™”)\n",
    "- ê°„ë‹¨í•œ êµ¬í˜„ (í•™ìƒ í”„ë¡œì íŠ¸ ì í•©)\n",
    "- íŒŒì¼ ì €ì¥/ë¡œë“œ ê°€ëŠ¥ (ì„ë² ë”© ì¬ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02571985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def create_faiss_index(embeddings, save_path=None):\n",
    "    \"\"\"\n",
    "    FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: ì„ë² ë”© ë²¡í„° ë°°ì—´ (numpy array)\n",
    "        save_path: ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ)\n",
    "    \n",
    "    Returns:\n",
    "        FAISS ì¸ë±ìŠ¤\n",
    "    \"\"\"\n",
    "    # ì¸ë±ìŠ¤ ìƒì„±\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    \n",
    "    # ë²¡í„° ì¶”ê°€\n",
    "    index.add(embeddings.astype('float32'))\n",
    "    \n",
    "    print(f\"âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "    print(f\"   - ì €ì¥ëœ ë²¡í„° ìˆ˜: {index.ntotal}ê°œ\")\n",
    "    print(f\"   - ë²¡í„° ì°¨ì›: {dimension}\")\n",
    "    \n",
    "    # ì¸ë±ìŠ¤ ì €ì¥\n",
    "    if save_path:\n",
    "        faiss.write_index(index, save_path)\n",
    "        print(f\"ğŸ’¾ FAISS ì¸ë±ìŠ¤ ì €ì¥: {save_path}\")\n",
    "    \n",
    "    return index\n",
    "\n",
    "def load_faiss_index(load_path):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        load_path: ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        FAISS ì¸ë±ìŠ¤\n",
    "    \"\"\"\n",
    "    index = faiss.read_index(load_path)\n",
    "    print(f\"âœ… ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {index.ntotal}ê°œ ë²¡í„°\")\n",
    "    return index\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "index = create_faiss_index(recipe_embeddings, save_path=\"recipe_faiss_100.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862c616",
   "metadata": {},
   "source": [
    "### FAISS ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_faiss(query_text, index, data, k=3):\n",
    "    \"\"\"\n",
    "    FAISSë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ ë ˆì‹œí”¼ ê²€ìƒ‰ (GPT Function Calling ìµœì í™”)\n",
    "    \n",
    "    Args:\n",
    "        query_text: ì‚¬ìš©ì ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        index: FAISS ì¸ë±ìŠ¤\n",
    "        data: ë ˆì‹œí”¼ DataFrame\n",
    "        k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ëœ ë ˆì‹œí”¼ ë¦¬ìŠ¤íŠ¸ [{\"title\": str, \"content\": str}]\n",
    "    \"\"\"\n",
    "    # ì¿¼ë¦¬ ì„ë² ë”©\n",
    "    query_embedding = np.array([get_embedding(query_text)]).astype('float32')\n",
    "    \n",
    "    # FAISS ê²€ìƒ‰\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # ê²°ê³¼ ë°˜í™˜\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        recipe = data.iloc[idx]\n",
    "        results.append({\n",
    "            \"title\": recipe['RCP_TTL'],\n",
    "            \"content\": recipe['ESSENTIAL_CONTENT']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_search_results(results, query):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "    \"\"\"\n",
    "    print(f\"\\nì¿¼ë¦¬: '{query}'\")\n",
    "    print(f\"ê²€ìƒ‰ ê²°ê³¼ {len(results)}ê°œ:\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. {result['title']}\")\n",
    "        print(f\"   ë‚´ìš©: {result['content'][:100]}...\")\n",
    "        print()\n",
    "\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:\")\n",
    "test_query = \"ë”°ëœ»í•œ êµ­ë¬¼ ìš”ë¦¬\"\n",
    "search_results = search_with_faiss(test_query, index, test_data, k=3)\n",
    "display_search_results(search_results, test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebecdcf1",
   "metadata": {},
   "source": [
    "### ì €ì¥ëœ ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° (ì„ íƒì‚¬í•­)\n",
    "\n",
    "ë‚˜ì¤‘ì— ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2707eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° ì˜ˆì‹œ\n",
    "# ë‚˜ì¤‘ì— ì¬ì‚¬ìš©í•  ë•Œ:\n",
    "# index = load_faiss_index(\"recipe_faiss_100.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15edb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_recipes(query_text, top_k=3):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ë˜í¼ í•¨ìˆ˜)\n",
    "    \n",
    "    Args:\n",
    "        query_text: ì‚¬ìš©ì ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ëœ ë ˆì‹œí”¼ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    return search_with_faiss(query_text, index, test_data, k=top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcbd98",
   "metadata": {},
   "source": [
    "### GPT Function Callingì„ ìœ„í•œ ë„êµ¬ ì •ì˜\n",
    "\n",
    "ë ˆì‹œí”¼ ê²€ìƒ‰ ë° ì¶”ì²œ ì‹œìŠ¤í…œì„ GPT Function Callingìœ¼ë¡œ ìµœì í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë„êµ¬**:\n",
    "- `search_recipes`: ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë ˆì‹œí”¼ ì¶”ì²œ\n",
    "- `get_user_sentiment`: ê°ì„± ë¶„ì„ ê¸°ë°˜ ìƒí™© íŒŒì•…\n",
    "\n",
    "ì´ ë„êµ¬ë“¤ì€ OpenAIì˜ Function Calling APIë¥¼ í†µí•´ GPTê°€ ìë™ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Function Callingì„ ìœ„í•œ ë„êµ¬ ì •ì˜\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_recipes\",\n",
    "            \"description\": \"ì‚¬ìš©ìì˜ ê²€ìƒ‰ ì¿¼ë¦¬ì— ê¸°ë°˜í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ìŒì‹ ì¢…ë¥˜, ì¬ë£Œ, ì¡°ë¦¬ë²•, ìƒí™© ë“±ì„ ê³ ë ¤í•˜ì—¬ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query_text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ë ˆì‹œí”¼ ê²€ìƒ‰ ì¿¼ë¦¬. ì˜ˆ: 'ë”°ëœ»í•œ êµ­ë¬¼ ìš”ë¦¬', 'ê°„ë‹¨í•œ ì•„ì¹¨ ë©”ë‰´', 'ë§¤ìš´ ì°Œê°œ'\"\n",
    "                    },\n",
    "                    \"top_k\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"ë°˜í™˜í•  ë ˆì‹œí”¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 3)\",\n",
    "                        \"default\": 3\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query_text\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_user_sentiment\",\n",
    "            \"description\": \"ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ê°ì„± ìƒíƒœë¥¼ íŒŒì•…í•©ë‹ˆë‹¤. ê¸ì •ì , ë¶€ì •ì , ì¤‘ë¦½ì  ê¸°ë¶„ì„ íŒë‹¨í•˜ì—¬ ë” ì ì ˆí•œ ë©”ë‰´ ì¶”ì²œì— í™œìš©í•©ë‹ˆë‹¤.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ê°ì„±ì„ ë¶„ì„í•  ì‚¬ìš©ì í…ìŠ¤íŠ¸\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"text\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"âœ… GPT Function Calling ë„êµ¬ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"ë“±ë¡ëœ ë„êµ¬: {len(tools)}ê°œ\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool['function']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e851c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def get_current_time():\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ì‹œê°„ì„ í•œêµ­ì–´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Returns:\n",
    "        í˜„ì¬ ì‹œê°„ ë¬¸ìì—´ (ì˜ˆ: \"ì˜¤í›„ 3ì‹œ 30ë¶„\")\n",
    "    \"\"\"\n",
    "    return datetime.now().strftime(\"%p %Iì‹œ %Më¶„\").replace(\"AM\", \"ì˜¤ì „\").replace(\"PM\", \"ì˜¤í›„\")\n",
    "\n",
    "def format_recipe_context(recipes):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë ˆì‹œí”¼ë¥¼ GPT í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        recipes: ë ˆì‹œí”¼ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        í¬ë§·íŒ…ëœ ë ˆì‹œí”¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    return \"\\n---\\n\".join([\n",
    "        f\"ì œëª©: {r['title']}\\në‚´ìš©: {r['content'][:200]}...\"\n",
    "        for r in recipes\n",
    "    ])\n",
    "\n",
    "def create_recommendation_prompt(user_input, sentiment_data, recipes, current_time):\n",
    "    \"\"\"\n",
    "    GPTì—ê²Œ ì „ë‹¬í•  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì…ë ¥\n",
    "        sentiment_data: ê°ì„± ë¶„ì„ ê²°ê³¼\n",
    "        recipes: ê²€ìƒ‰ëœ ë ˆì‹œí”¼ ë¦¬ìŠ¤íŠ¸\n",
    "        current_time: í˜„ì¬ ì‹œê°„\n",
    "    \n",
    "    Returns:\n",
    "        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    recipe_context = format_recipe_context(recipes)\n",
    "    \n",
    "    return f\"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í˜„ì¬ ìƒí™©ê³¼ ì„ í˜¸ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ë§ì¶¤í˜• ë©”ë‰´ë¥¼ ì¶”ì²œí•˜ëŠ” ì¹œì ˆí•œ ìš”ë¦¬ì‚¬ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒì˜ ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì¶”ì²œì„ ì§„í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "1. **í˜„ì¬ ìƒí™©**: {current_time}, ì‚¬ìš©ìì˜ ê°ì„±: {sentiment_data['description']} (ì ìˆ˜: {sentiment_data['score']:.2f})\n",
    "2. **ê²€ìƒ‰ëœ ê´€ë ¨ ë ˆì‹œí”¼**:\n",
    "---\n",
    "{recipe_context}\n",
    "---\n",
    "\n",
    "ê²€ìƒ‰ëœ ë ˆì‹œí”¼ ì¤‘ì—ì„œ ì‚¬ìš©ìì˜ ê°ì„±/ìƒí™©ì— ê°€ì¥ ì í•©í•œ ë©”ë‰´ 1~2ê°œë¥¼ **ì„ íƒí•˜ê³ **, ì™œ ê·¸ê²ƒì´ ì¢‹ì€ì§€ ê°„ê²°í•˜ê³  ë§¤ë ¥ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\"\"\"\n",
    "\n",
    "def recommend_with_rag(user_input):\n",
    "    \"\"\"\n",
    "    RAG ê¸°ë°˜ ë©”ë‰´ ì¶”ì²œ ì‹œìŠ¤í…œ (GPT Function Calling ìµœì í™”)\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        GPT ì¶”ì²œ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # sentiment_module import\n",
    "        from sentiment_module import get_user_sentiment\n",
    "        \n",
    "        # 1. ìƒí™© íŒŒì•…\n",
    "        sentiment_data = get_user_sentiment(user_input)\n",
    "        current_time = get_current_time()\n",
    "        \n",
    "        # 2. ë ˆì‹œí”¼ ê²€ìƒ‰\n",
    "        search_query = f\"{user_input} ({sentiment_data['description']}ì— ì–´ìš¸ë¦¬ëŠ” ë©”ë‰´)\"\n",
    "        retrieved_recipes = search_recipes(search_query, top_k=3)\n",
    "        \n",
    "        # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        system_prompt = create_recommendation_prompt(\n",
    "            user_input, sentiment_data, retrieved_recipes, current_time\n",
    "        )\n",
    "        \n",
    "        # 4. GPT API í˜¸ì¶œ\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "\n",
    "def recommend_with_function_calling(user_input):\n",
    "    \"\"\"\n",
    "    GPT Function Callingì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì¶”ì²œ ì‹œìŠ¤í…œ\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        GPT ì¶”ì²œ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í˜„ì¬ ìƒí™©ê³¼ ì„ í˜¸ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ë§ì¶¤í˜• ë©”ë‰´ë¥¼ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê°ì„±ì„ ë¶„ì„í•˜ê³ , ê´€ë ¨ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìµœì ì˜ ë©”ë‰´ë¥¼ ì¶”ì²œí•˜ì„¸ìš”.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "        \n",
    "        # GPTì—ê²Œ ë„êµ¬ ì‚¬ìš© ê¶Œí•œ ë¶€ì—¬\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬\n",
    "        response_message = response.choices[0].message\n",
    "        \n",
    "        if response_message.tool_calls:\n",
    "            # ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ìˆ˜ì§‘\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if function_name == \"search_recipes\":\n",
    "                    function_response = search_recipes(**function_args)\n",
    "                elif function_name == \"get_user_sentiment\":\n",
    "                    from sentiment_module import get_user_sentiment\n",
    "                    function_response = get_user_sentiment(**function_args)\n",
    "                \n",
    "                # ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€\n",
    "                messages.append(response_message)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(function_response, ensure_ascii=False)\n",
    "                })\n",
    "            \n",
    "            # ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "            final_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            return final_response.choices[0].message.content\n",
    "        else:\n",
    "            return response_message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ½ï¸ RAG ê¸°ë°˜ ë©”ë‰´ ì¶”ì²œ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "user_query = \"ì˜¤ëŠ˜ ì¢€ í”¼ê³¤í•˜ê³  ë”°ëœ»í•˜ê³  ìœ„ë¡œê°€ ë˜ëŠ” ìŒì‹ì´ ë¨¹ê³  ì‹¶ì–´.\"\n",
    "recommendation = recommend_with_rag(user_query)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d23698",
   "metadata": {},
   "source": [
    "### í•¨ìˆ˜ ìš”ì•½\n",
    "\n",
    "ì´ì œ ëª¨ë“  ê¸°ëŠ¥ì´ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "**ë°ì´í„° ì²˜ë¦¬**:\n",
    "- `load_recipe_data()`: CSV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "- `prepare_embedding_data()`: ì„ë² ë”©ìš© ë°ì´í„° ì¤€ë¹„\n",
    "- `create_essential_content()`: í•µì‹¬ ì •ë³´ ì¶”ì¶œ\n",
    "- `extract_essential_info()`: ì „ì²´ ë°ì´í„° í•µì‹¬ ì •ë³´ ì¶”ì¶œ\n",
    "\n",
    "**í† í° ê´€ë¦¬**:\n",
    "- `count_tokens()`: í† í° ìˆ˜ ê³„ì‚°\n",
    "- `analyze_token_statistics()`: í† í° í†µê³„ ë¶„ì„\n",
    "\n",
    "**ì„ë² ë”© & ê²€ìƒ‰**:\n",
    "- `get_embedding()`: OpenAI ì„ë² ë”© ìƒì„±\n",
    "- `generate_embeddings()`: ë°°ì¹˜ ì„ë² ë”© ìƒì„±\n",
    "- `create_faiss_index()`: FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥\n",
    "- `load_faiss_index()`: ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ\n",
    "- `search_with_faiss()`: FAISS ê²€ìƒ‰\n",
    "- `search_recipes()`: ë˜í¼ ê²€ìƒ‰ í•¨ìˆ˜\n",
    "\n",
    "**GPT ì¶”ì²œ**:\n",
    "- `get_current_time()`: í˜„ì¬ ì‹œê°„ í¬ë§·íŒ…\n",
    "- `format_recipe_context()`: ë ˆì‹œí”¼ í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n",
    "- `create_recommendation_prompt()`: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "- `recommend_with_rag()`: ê¸°ë³¸ RAG ì¶”ì²œ\n",
    "- `recommend_with_function_calling()`: GPT Function Calling ì¶”ì²œ\n",
    "\n",
    "**ìœ í‹¸ë¦¬í‹°**:\n",
    "- `display_search_results()`: ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4052d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë‹¤ìŒ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   1. ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬            â”‚\n",
    "â”‚   - CSV íŒŒì¼ ë¡œë“œ                   â”‚\n",
    "â”‚   - í•µì‹¬ ì •ë³´ ì¶”ì¶œ (í† í° ì ˆê° 70%)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   2. ì„ë² ë”© ìƒì„± (OpenAI)           â”‚\n",
    "â”‚   - text-embedding-3-small          â”‚\n",
    "â”‚   - ë°°ì¹˜ ì²˜ë¦¬ (100ê°œ ìƒ˜í”Œ)          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   3. FAISS ë²¡í„° ê²€ìƒ‰ ì¸ë±ìŠ¤         â”‚\n",
    "â”‚   - L2 ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°        â”‚\n",
    "â”‚   - ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥/ì¬ì‚¬ìš©         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   4. GPT Function Calling           â”‚\n",
    "â”‚   - ìë™ ë„êµ¬ ì„ íƒ                  â”‚\n",
    "â”‚   - ê°ì„± ë¶„ì„ + ë ˆì‹œí”¼ ê²€ìƒ‰ í†µí•©    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**ê¸°ìˆ  ìŠ¤íƒ**: Python, OpenAI API, FAISS, HuggingFace Transformers, pandas, tiktoken\n",
    "\n",
    "**í•µì‹¬ ì„±ê³¼**:\n",
    "- âœ… í† í° ì‚¬ìš©ëŸ‰ 70% ì ˆê° (ë¹„ìš© íš¨ìœ¨ì„±)\n",
    "- âœ… FAISS ê²€ìƒ‰ ì†ë„ < 100ms (23K ë ˆì‹œí”¼ ëŒ€ìƒ)\n",
    "- âœ… Function Callingìœ¼ë¡œ GPT ììœ¨ ë„êµ¬ ì„ íƒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
