"""LangGraph-based stateful recommendation workflow.

This module implements a graph-based workflow for menu recommendations
with state management, multi-step reasoning, and conditional routing.
"""
from __future__ import annotations
from typing import TypedDict, Annotated, Sequence, Literal, NotRequired
from datetime import datetime
import operator
import json
import logging

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode

logger = logging.getLogger("recommendation_workflow")


# -------------------- State Definition --------------------

class RecommendationState(TypedDict):
    """State schema for recommendation workflow.
    
    Tracks conversation history, user input, search results,
    sentiment data, user profile, and final recommendations.
    """
    messages: Annotated[Sequence[BaseMessage], operator.add]
    user_input: str
    user_profile: NotRequired[dict]  # ì‚¬ì´ë“œë°” í”„ë¡œí•„ ì •ë³´ (ì„ íƒì )
    sentiment_data: dict
    search_results: list
    recommendations: list
    current_time: str
    iteration_count: int


# -------------------- Node Functions --------------------

def analyze_sentiment_node(state: RecommendationState) -> RecommendationState:
    """Analyze user sentiment from input.
    
    Args:
        state: Current workflow state.
    
    Returns:
        Updated state with sentiment_data.
    """
    try:
        from sentiment_module import get_user_sentiment
        sentiment = get_user_sentiment(state["user_input"])
        logger.info(f"Sentiment analysis: {sentiment.get('description')}")
    except Exception as e:
        logger.warning(f"Sentiment analysis failed: {e}, using neutral")
        sentiment = {"label": "NEUTRAL", "score": 0.5, "description": "ì¤‘ë¦½ì ì¸ ê¸°ë¶„"}
    
    return {
        **state,
        "sentiment_data": sentiment,
        "messages": state["messages"] + [
            SystemMessage(content=f"ê°ì„± ë¶„ì„ ì™„ë£Œ: {sentiment.get('description')} (ì ìˆ˜: {sentiment.get('score', 0):.2f})")
        ],
    }


def search_recipes_node(state: RecommendationState, retriever) -> RecommendationState:
    """Search for relevant recipes.
    
    Args:
        state: Current workflow state.
        retriever: FAISSRecipeRetriever instance.
    
    Returns:
        Updated state with search_results.
    """
    query = state["user_input"]
    
    # Enhance query with sentiment if available
    if state.get("sentiment_data"):
        sentiment_desc = state["sentiment_data"].get("description", "")
        if "ê¸ì •" in sentiment_desc or "ë¶€ì •" in sentiment_desc:
            query = f"{query} ({sentiment_desc})"
    
    # í”„ë¡¬í”„íŠ¸ì—ì„œ ë¹„ê±´/ì±„ì‹ ê°ì§€ (ê²€ìƒ‰ ì „ì— ë¯¸ë¦¬ í™•ì¸)
    user_input_lower = state.get('user_input', '').lower()
    prompt_vegan = any(k in user_input_lower for k in ['ë¹„ê±´', 'vegan', 'ì±„ì‹'])
    profile = state.get('user_profile', {})
    is_vegan = profile.get('diet') == 'vegan' or prompt_vegan
    
    # ì¿¼ë¦¬ ê°œì„ : ë¹„ê±´ì´ë©´ ì‹ë¬¼ì„± ë‹¨ë°±ì§ˆ í‚¤ì›Œë“œ ì¶”ê°€
    if is_vegan and any(k in user_input_lower for k in ['ë‹¨ë°±ì§ˆ', 'ì˜ì–‘']):
        query = f"{query} ë‘ë¶€ ì½© ê²¬ê³¼ë¥˜"
        logger.info(f"[SEARCH] ë¹„ê±´ ë‹¨ë°±ì§ˆ ì¿¼ë¦¬ ê°•í™”: {query}")
    
    # ë¹„ê±´/ì±„ì‹ì´ë©´ ë” ë§ì´ ê²€ìƒ‰ (í•„í„°ë§ìœ¼ë¡œ ë§ì´ ì œê±°ë˜ë¯€ë¡œ)
    search_k = 50 if is_vegan else 10
    
    # Use vectorstore directly for k control
    docs = retriever.vectorstore.similarity_search(query, k=search_k)
    
    results = [
        {
            "title": doc.metadata.get("title", ""),
            "content": doc.page_content[:200],
            "category": doc.metadata.get("category", ""),
            "full_content": doc.page_content  # í•„í„°ë§ìš© ì „ì²´ ë‚´ìš©
        }
        for doc in docs
    ]
    
    logger.info(f"Retrieved {len(results)} recipes (before filtering)")
    
    # ==================== í”„ë¡œí•„ + í”„ë¡¬í”„íŠ¸ í†µí•© ê°ì§€ ====================
    # í”„ë¡¬í”„íŠ¸ ì±„ì‹ í‚¤ì›Œë“œ ê°ì§€
    prompt_vegetarian = any(k in user_input_lower for k in ['ì±„ì‹'])
    is_vegetarian = profile.get('diet') == 'vegetarian' or (prompt_vegetarian and not prompt_vegan)
    
    filtered_results = results
    
    # ì‹ë‹¨ ì œì•½ í•„í„°ë§
    if is_vegan or is_vegetarian:
        # ì‹ë‹¨ ì œì•½ í•„í„°ë§ (í™•ì¥ëœ ì œì™¸ ëª©ë¡)
        vegan_exclude = [
            # ìœ¡ë¥˜
            'ê³ ê¸°', 'ì‡ ê³ ê¸°', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ë‹­', 'ì–‘ê³ ê¸°', 'ì˜¤ë¦¬ê³ ê¸°', 'ì‚¼ê²©ì‚´', 'ëª©ì‚´', 'í•­ì •ì‚´', 'ë“±ì‹¬', 'ì•ˆì‹¬', 'ê°ˆë¹„', 'ì°¨ëŒ', 'ì‚¬íƒœ', 'ì–‘ì§€', 'ìš°ì‚¼ê²©',
            # ë‹¬ê±€/ìœ ì œí’ˆ
            'ë‹¬ê±€', 'ê³„ë€', 'ì¹˜ì¦ˆ', 'ë²„í„°', 'ìš°ìœ ', 'í¬ë¦¼', 'ìš”êµ¬ë¥´íŠ¸', 'ìƒí¬ë¦¼', 'ë…¸ë¥¸ì', 'í°ì',
            # í•´ì‚°ë¬¼ (ì „ì²´)
            'ìƒì„ ', 'í•´ì‚°ë¬¼', 'ë‹¤ìŠ¬ê¸°', 'êµ´', 'ì¡°ê°œ', 'ìƒˆìš°', 'ê²Œ', 'ì˜¤ì§•ì–´', 'ë‚™ì§€', 'ë¬¸ì–´', 'ì£¼ê¾¸ë¯¸',
            'ê³ ë“±ì–´', 'ê°ˆì¹˜', 'ê½ì¹˜', 'ì°¸ì¹˜', 'ì—°ì–´', 'ê´‘ì–´', 'ìš°ëŸ­', 'ì¡°ê¸°', 'ë©¸ì¹˜', 'ë¶ì–´', 'ëª…íƒœ', 'ëŒ€êµ¬', 'ë™íƒœ',
            'ì¡°ê°¯ì‚´', 'í™í•©', 'ë°”ì§€ë½', 'ê°€ë¦¬ë¹„', 'ì „ë³µ', 'ì†Œë¼', 'í•´ë¬¼', 'ì–´ë¬µ', 'ì˜¤ë±', 'ê³¨ë±…ì´',
            # íŠ¹ìˆ˜ ë™ë¬¼ì„±
            'ì„ ì§€', 'ê³±ì°½', 'ë§‰ì°½', 'ëª…ë€', 'ì°½ë€', 'ì•Œíƒ•', 'ì “ê°ˆ', 'ê¹Œë‚˜ë¦¬', 'ì•¡ì “',
            # ê°€ê³µìœ¡
            'ë² ì´ì»¨', 'ì†Œì‹œì§€', 'í–„', 'ìŠ¤íŒ¸', 'ìœ¡í¬', 'ë² ì»¨'
        ]
        vegetarian_exclude = [
            # ìœ¡ë¥˜
            'ê³ ê¸°', 'ì‡ ê³ ê¸°', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ì–‘ê³ ê¸°', 'ì˜¤ë¦¬ê³ ê¸°', 'ì‚¼ê²¹ì‚´', 'ëª©ì‚´', 'í•­ì •ì‚´', 'ë“±ì‹¬', 'ì•ˆì‹¬', 'ê°ˆë¹„', 'ì°¨ëŒ', 'ì‚¬íƒœ', 'ì–‘ì§€',
            # í•´ì‚°ë¬¼
            'ìƒì„ ', 'í•´ì‚°ë¬¼', 'ë‹¤ìŠ¬ê¸°', 'êµ´', 'ì¡°ê°œ', 'ìƒˆìš°', 'ê²Œ', 'ì˜¤ì§•ì–´', 'ë‚™ì§€', 'ë¬¸ì–´', 'ì£¼ê¾¸ë¯¸',
            'ê³ ë“±ì–´', 'ê°ˆì¹˜', 'ê½ì¹˜', 'ì°¸ì¹˜', 'ì—°ì–´', 'ê´‘ì–´', 'ìš°ëŸ­', 'ì¡°ê¸°', 'ë©¸ì¹˜', 'ë¶ì–´', 'ëª…íƒœ', 'ëŒ€êµ¬',
            'ì–´ë¬µ', 'ì˜¤ë…', 'í•´ë¬¼',
            # íŠ¹ìˆ˜ ë™ë¬¼ì„±
            'ì„ ì§€', 'ê³±ì°½', 'ë§‰ì°½', 'ëª…ë€', 'ì°½ë€', 'ì•Œíƒ•', 'ì “ê°ˆ', 'ê¹Œë‚˜ë¦¬', 'ì•¡ì “',
            # ê°€ê³µìœ¡
            'ë² ì´ì»¨', 'ì†Œì‹œì§€', 'í–„', 'ìŠ¤íŒ¸', 'ìœ¡í¬'
        ]
        
        diet_exclude = []
        if is_vegan:
            diet_exclude = vegan_exclude
            source = "í”„ë¡¬í”„íŠ¸" if prompt_vegan else "ì‚¬ì´ë“œë°”"
            logger.info(f"[FILTER] ë¹„ê±´ í•„í„°ë§ ì ìš© ({source}): {len(vegan_exclude)}ê°œ ì¬ë£Œ ì œì™¸")
        elif is_vegetarian:
            diet_exclude = vegetarian_exclude
            source = "í”„ë¡¬í”„íŠ¸" if prompt_vegetarian else "ì‚¬ì´ë“œë°”"
            logger.info(f"[FILTER] ì±„ì‹ í•„í„°ë§ ì ìš© ({source}): {len(vegetarian_exclude)}ê°œ ì¬ë£Œ ì œì™¸")
        
        if diet_exclude:
            before_count = len(filtered_results)
            filtered_results = [
                r for r in filtered_results
                if not any(excluded in r['title'] + r.get('full_content', '') for excluded in diet_exclude)
            ]
            removed = before_count - len(filtered_results)
            logger.info(f"[FILTER] ì‹ë‹¨ ì œì•½ í›„: {before_count} -> {len(filtered_results)}ê°œ ({removed}ê°œ ì œê±°)")
    
    # ì•Œë ˆë¥´ê¸° í•„í„°ë§ (í”„ë¡œí•„ë§Œ ì‚¬ìš©)
    if profile and profile.get('allergies'):
        before_count = len(filtered_results)
        filtered_results = [
            r for r in filtered_results
            if not any(allergy.lower() in r['title'].lower() + r.get('full_content', '').lower() for allergy in profile['allergies'])
        ]
        removed = before_count - len(filtered_results)
        logger.info(f"[FILTER] ì•Œë ˆë¥´ê¸° í•„í„° í›„: {before_count} -> {len(filtered_results)}ê°œ ({removed}ê°œ ì œê±°)")
    
    # ìµœì¢… ê²°ê³¼ (ìµœëŒ€ 5ê°œ)
    final_results = filtered_results[:5]
    logger.info(f"Retrieved {len(final_results)} recipes (after filtering)")
    
    return {
        **state,
        "search_results": final_results,
        "messages": state["messages"] + [
            SystemMessage(content=f"ë ˆì‹œí”¼ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ë°œê²¬")
        ],
    }


def generate_recommendations_node(state: RecommendationState, llm: ChatOpenAI) -> RecommendationState:
    """Generate final recommendations using LLM.
    
    Args:
        state: Current workflow state.
        llm: ChatOpenAI instance.
    
    Returns:
        Updated state with recommendations.
    """
    # Build context from search results
    if state["search_results"]:
        context = "\n---\n".join([
            f"ì œëª©: {r['title']}\në‚´ìš©: {r['content']}"
            for r in state["search_results"]
        ])
    else:
        context = "ê²€ìƒ‰ëœ ë ˆì‹œí”¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”."
    
    sentiment_desc = state.get("sentiment_data", {}).get("description", "ì¤‘ë¦½ì ì¸ ê¸°ë¶„")
    sentiment_score = state.get("sentiment_data", {}).get("score", 0.5)
    
    # ==================== í”„ë¡œí•„ + í”„ë¡¬í”„íŠ¸ í†µí•© ë¶„ì„ ====================
    user_input_lower = state['user_input'].lower()
    profile = state.get('user_profile', {})
    
    dietary_restrictions = []
    allergies_list = []
    preferences = []
    requirements = []
    
    # 1. ì‚¬ì´ë“œë°” í”„ë¡œí•„ ì •ë³´ (ìµœìš°ì„ )
    if profile.get('diet'):
        if profile['diet'] == 'vegan':
            dietary_restrictions.append("ğŸš« ë¹„ê±´ ì‹ë‹¨ (ì‚¬ì´ë“œë°”): ê³ ê¸°, ë‹­ê³ ê¸°, ë¼ì§€ê³ ê¸°, ì‡ ê³ ê¸°, ë‹¬ê±€, ìš°ìœ , ì¹˜ì¦ˆ, ë²„í„°, ìƒì„ , í•´ì‚°ë¬¼ ì ˆëŒ€ ê¸ˆì§€")
        elif profile['diet'] == 'vegetarian':
            dietary_restrictions.append("ğŸš« ì±„ì‹ (ì‚¬ì´ë“œë°”): ê³ ê¸°, ë‹­ê³ ê¸°, ë¼ì§€ê³ ê¸°, ì‡ ê³ ê¸°, ìƒì„ , í•´ì‚°ë¬¼ ì ˆëŒ€ ê¸ˆì§€")
        elif profile['diet'] == 'low_sodium':
            dietary_restrictions.append("ğŸš« ì €ì—¼ì‹ (ì‚¬ì´ë“œë°”): ì†Œê¸ˆ, ê°„ì¥, ì•¡ì “, ì “ê°ˆ ìµœì†Œí™”")
    
    if profile.get('allergies'):
        allergy_items = ', '.join(profile['allergies'])
        allergies_list.append(f"âš ï¸ ì•Œë ˆë¥´ê¸° (ì‚¬ì´ë“œë°”): {allergy_items} í¬í•¨ ë ˆì‹œí”¼ ì ˆëŒ€ ê¸ˆì§€")
    
    if profile.get('preferred_flavors'):
        pref_items = ', '.join(profile['preferred_flavors'])
        preferences.append(f"âœ… ì„ í˜¸ ë§› (ì‚¬ì´ë“œë°”): {pref_items} ìš°ì„ ")
    
    if profile.get('disliked_flavors'):
        dislike_items = ', '.join(profile['disliked_flavors'])
        preferences.append(f"âŒ ë¹„ì„ í˜¸ ë§› (ì‚¬ì´ë“œë°”): {dislike_items} ì œì™¸")
    
    # 2. í”„ë¡¬í”„íŠ¸ í‚¤ì›Œë“œ ê°ì§€ (ì‚¬ì´ë“œë°”ì— ì—†ìœ¼ë©´ ì¶”ê°€)
    # ì‹ë‹¨ ì œì•½
    if any(k in user_input_lower for k in ['ë¹„ê±´', 'vegan', 'ì±„ì‹']) and not profile.get('diet'):
        dietary_restrictions.append("ğŸš« ë¹„ê±´/ì±„ì‹ (ì…ë ¥): ê³ ê¸°, ë‹­ê³ ê¸°, ë¼ì§€ê³ ê¸°, ì‡ ê³ ê¸°, ë‹¬ê±€, ìš°ìœ , ì¹˜ì¦ˆ, ë²„í„°, ìƒì„ , í•´ì‚°ë¬¼ ì ˆëŒ€ ê¸ˆì§€")
    if any(k in user_input_lower for k in ['ì €ì—¼', 'ì†Œê¸ˆê¸ˆì§€', 'ì‹±ê²ê²Œ']) and profile.get('diet') != 'low_sodium':
        dietary_restrictions.append("ğŸš« ì €ì—¼ì‹ (ì…ë ¥): ì†Œê¸ˆ, ê°„ì¥, ì•¡ì “, ì “ê°ˆ ìµœì†Œí™”")
    
    # ì•Œë ˆë¥´ê¸° í‚¤ì›Œë“œ
    allergy_keywords = {
        'ë•…ì½©': ['ë•…ì½©', 'í”¼ë„›'],
        'ìš°ìœ ': ['ìš°ìœ ', 'ìœ ì œí’ˆ', 'ìœ ë‹¹ë¶ˆë‚´'],
        'ë‹¬ê±€': ['ë‹¬ê±€', 'ê³„ë€'],
        'ê°‘ê°ë¥˜': ['ìƒˆìš°', 'ê²Œ', 'ê°‘ê°ë¥˜'],
        'ê²¬ê³¼ë¥˜': ['í˜¸ë‘', 'ì•„ëª¬ë“œ', 'ê²¬ê³¼ë¥˜']
    }
    for allergy, keywords in allergy_keywords.items():
        if any(k in user_input_lower for k in keywords) and (not profile.get('allergies') or allergy not in profile['allergies']):
            allergies_list.append(f"âš ï¸ ì•Œë ˆë¥´ê¸° (ì…ë ¥): {allergy} í¬í•¨ ë ˆì‹œí”¼ ì ˆëŒ€ ê¸ˆì§€")
    
    # ì„ í˜¸/ë¹„ì„ í˜¸ ë§›
    if any(k in user_input_lower for k in ['ë§¤ìš´', 'ë§¤ì½¤', 'ì¹¼ì¹¼']):
        preferences.append("âœ… ì„ í˜¸ ë§› (ì…ë ¥): ë§¤ìš´ë§› ìš°ì„ ")
    if any(k in user_input_lower for k in ['ë‹¬ì½¤', 'ë‹¨ë§›']):
        preferences.append("âœ… ì„ í˜¸ ë§› (ì…ë ¥): ë‹¨ë§› ìš°ì„ ")
    if any(k in user_input_lower for k in ['ì•ˆë§¤ìš´', 'ë§µì§€ì•Šì€', 'ìˆœí•œ']):
        preferences.append("âŒ ë¹„ì„ í˜¸ ë§› (ì…ë ¥): ë§¤ìš´ë§› ì œì™¸")
    
    # 3. ìš”ë¦¬ íƒ€ì…
    if any(k in user_input_lower for k in ['ì–‘ì‹', 'ì„œì–‘', 'ì´íƒˆë¦¬ì•ˆ', 'íŒŒìŠ¤íƒ€', 'ìŠ¤í…Œì´í¬']):
        requirements.append("âš ï¸ ì¤‘ìš”: ì–‘ì‹/ì„œì–‘ ìš”ë¦¬ë§Œ ì¶”ì²œ")
    elif any(k in user_input_lower for k in ['í•œì‹', 'í•œêµ­', 'ê¹€ì¹˜', 'ëœì¥']):
        requirements.append("âš ï¸ ì¤‘ìš”: í•œì‹ ìš”ë¦¬ë§Œ ì¶”ì²œ")
    elif any(k in user_input_lower for k in ['ì¤‘ì‹', 'ì¤‘êµ­', 'ì§œì¥', 'ì§¬ë½•']):
        requirements.append("âš ï¸ ì¤‘ìš”: ì¤‘ì‹ ìš”ë¦¬ë§Œ ì¶”ì²œ")
    elif any(k in user_input_lower for k in ['ì¼ì‹', 'ì¼ë³¸', 'ìŠ¤ì‹œ', 'ë¼ë©˜']):
        requirements.append("âš ï¸ ì¤‘ìš”: ì¼ì‹ ìš”ë¦¬ë§Œ ì¶”ì²œ")
    
    # 4. ê¸°íƒ€ ì œì•½
    if any(k in user_input_lower for k in ['ê°„ë‹¨', 'ì‰¬ìš´', 'ë¹ ë¥¸', '10ë¶„', '5ë¶„']):
        requirements.append("ì¡°ë¦¬ ì‹œê°„ì´ ì§§ì€ ë ˆì‹œí”¼ ìš°ì„ ")
    if any(k in user_input_lower for k in ['ë‹¨ë°±ì§ˆ', 'ë‘ë¶€', 'ì½©']) and 'ê³ ê¸°' not in user_input_lower:
        requirements.append("ë‹¨ë°±ì§ˆì´ í’ë¶€í•œ ë ˆì‹œí”¼ ìš°ì„ ")
    
    # 5. í†µí•© (ìš°ì„ ìˆœìœ„: ì‹ë‹¨ ì œì•½ > ì•Œë ˆë¥´ê¸° > ì„ í˜¸ë„ > ê¸°íƒ€)
    all_requirements = dietary_restrictions + allergies_list + preferences + requirements
    requirements_text = "\\n".join(all_requirements) if all_requirements else "ì‚¬ìš©ì ìš”ì²­ì— ì •í™•íˆ ë¶€í•©í•˜ëŠ” ë ˆì‹œí”¼ ì¶”ì²œ"
    
    # ë””ë²„ê·¸ ë¡œê·¸
    logger.info(f"[PROFILE+PROMPT] í†µí•© ìš”êµ¬ì‚¬í•­: {len(all_requirements)}ê°œ")
    if dietary_restrictions:
        logger.info(f"  - ì‹ë‹¨ ì œì•½: {dietary_restrictions}")
    if allergies_list:
        logger.info(f"  - ì•Œë ˆë¥´ê¸°: {allergies_list}")
    if preferences:
        logger.info(f"  - ì„ í˜¸ë„: {preferences}")
    
    prompt = f"""ë‹¹ì‹ ì€ ì‹ ë¢° ê¸°ë°˜ í•œêµ­ì–´ ë ˆì‹œí”¼ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

<CONTEXT>
í˜„ì¬ ì‹œê°„: {state.get('current_time', get_current_time())}
ì‚¬ìš©ì ê°ì„±: {sentiment_desc} (ì ìˆ˜: {sentiment_score:.2f})

ê²€ìƒ‰ëœ ë ˆì‹œí”¼:
{context}
</CONTEXT>

<USER_REQUEST>
{state['user_input']}

í•µì‹¬ ìš”êµ¬ì‚¬í•­:
{requirements_text}
</USER_REQUEST>

ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
{{
    "recommendations": [
        {{
            "title": "ë©”ë‰´ëª…",
            "reason": "ì¶”ì²œ ì´ìœ  (180ì ì´í•˜)",
            "match_factors": ["ê°ì„±", "ì¬ë£Œ", "ì‹œê°„"]
        }}
    ],
    "sentiment": "{sentiment_desc}",
    "timestamp": "{state.get('current_time', get_current_time())}"
}}

ê·œì¹™:
- ìµœëŒ€ 2ê°œ ì¶”ì²œ
- **ğŸš« ì‹ë‹¨ ì œì•½ì„ ì ˆëŒ€ì ìœ¼ë¡œ ì¤€ìˆ˜** (ì˜ˆ: ë¹„ê±´ì´ë©´ ë‹¬ê±€/ìš°ìœ /ê³ ê¸°/ìƒì„  í¬í•¨ ë ˆì‹œí”¼ ì ˆëŒ€ ê¸ˆì§€)
- **í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ì¶©ì¡±** (ì˜ˆ: ì–‘ì‹ ìš”ì²­ ì‹œ í•œì‹ ì¶”ì²œ ê¸ˆì§€)
- ë‹¤ì–‘ì„± í™•ë³´ (ì£¼ì¬ë£Œ/ì¡°ë¦¬ë²• ì¤‘ë³µ ë°©ì§€)
- reason ì²« ë¬¸ì¥ì— ê°ì„± ë°˜ì˜
- ê²€ìƒ‰ ê²°ê³¼ì— ì í•©í•œ ë ˆì‹œí”¼ê°€ ì—†ìœ¼ë©´ "ê²€ìƒ‰ ê²°ê³¼ì— ì í•©í•œ ë ˆì‹œí”¼ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ
- JSONë§Œ ì¶œë ¥
"""
    
    messages = [HumanMessage(content=prompt)]
    response = llm.invoke(messages)
    
    try:
        # Parse JSON response
        content = response.content
        # Extract JSON if wrapped in markdown
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        
        recommendations_data = json.loads(content)
        recommendations = recommendations_data.get("recommendations", [])
        logger.info(f"Generated {len(recommendations)} recommendations")
    except Exception as e:
        logger.error(f"Failed to parse recommendations: {e}")
        recommendations = [
            {
                "title": "ì˜¤ë¥˜ ë°œìƒ",
                "reason": "ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "match_factors": []
            }
        ]
    
    return {
        **state,
        "recommendations": recommendations,
        "messages": state["messages"] + [AIMessage(content=json.dumps(recommendations_data, ensure_ascii=False, indent=2))],
    }


def get_current_time() -> str:
    """Get formatted current time."""
    return datetime.now().strftime("%p %Iì‹œ %Më¶„").replace("AM", "ì˜¤ì „").replace("PM", "ì˜¤í›„")


# -------------------- Routing Functions --------------------

def should_search_recipes(state: RecommendationState) -> Literal["search", "skip_search"]:
    """Determine if recipe search is needed.
    
    Args:
        state: Current workflow state.
    
    Returns:
        "search" if search needed, "skip_search" otherwise.
    """
    # Always search unless user explicitly requests sentiment-only response
    user_input_lower = state["user_input"].lower()
    if "ê¸°ë¶„" in user_input_lower and "ì¶”ì²œ" not in user_input_lower:
        return "skip_search"
    return "search"


# -------------------- Graph Construction --------------------

def create_recommendation_graph(retriever, llm: ChatOpenAI | None = None):
    """Create LangGraph workflow for menu recommendations.
    
    Args:
        retriever: FAISSRecipeRetriever instance.
        llm: ChatOpenAI instance (default: gpt-4o).
    
    Returns:
        Compiled StateGraph.
    """
    if llm is None:
        llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
    
    # Create graph
    workflow = StateGraph(RecommendationState)
    
    # Add nodes
    workflow.add_node("analyze_sentiment", analyze_sentiment_node)
    workflow.add_node("search_recipes", lambda state: search_recipes_node(state, retriever))
    workflow.add_node("generate_recommendations", lambda state: generate_recommendations_node(state, llm))
    
    # Add edges
    workflow.set_entry_point("analyze_sentiment")
    
    # Conditional routing after sentiment analysis
    workflow.add_conditional_edges(
        "analyze_sentiment",
        should_search_recipes,
        {
            "search": "search_recipes",
            "skip_search": "generate_recommendations",
        }
    )
    
    workflow.add_edge("search_recipes", "generate_recommendations")
    workflow.add_edge("generate_recommendations", END)
    
    # Compile graph
    app = workflow.compile()
    
    logger.info("âœ… Created LangGraph recommendation workflow")
    return app


def run_recommendation_workflow(graph, user_input: str, user_profile: dict = None) -> dict:
    """Execute recommendation workflow.
    
    Args:
        graph: Compiled StateGraph.
        user_input: User query string.
        user_profile: User profile dict (allergies, diet, preferences).
    
    Returns:
        Final state dict with recommendations.
    """
    initial_state = {
        "messages": [HumanMessage(content=user_input)],
        "user_input": user_input,
        "user_profile": user_profile or {},
        "sentiment_data": {},
        "search_results": [],
        "recommendations": [],
        "current_time": get_current_time(),
        "iteration_count": 0,
    }
    
    logger.info(f"Starting workflow for: {user_input[:50]}...")
    logger.info(f"Profile: {user_profile}")
    final_state = graph.invoke(initial_state)
    
    return final_state
